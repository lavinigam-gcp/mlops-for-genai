{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bCIMTPB1WoTq"
      },
      "outputs": [],
      "source": [
        "# Copyright 2024 Google LLC\n",
        "#\n",
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "#     https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7yVV6txOmNMn"
      },
      "source": [
        "# Basic prototyping of the solution with Vertex AI Gemini API\n",
        "\n",
        "\n",
        "<table align=\"left\">\n",
        "  <td style=\"text-align: center\">\n",
        "    <a href=\"https://colab.research.google.com/github/GoogleCloudPlatform/generative-ai/blob/main/gemini/getting-started/intro_gemini_1_5_pro.ipynb\">\n",
        "      <img src=\"https://cloud.google.com/ml-engine/images/colab-logo-32px.png\" alt=\"Google Colaboratory logo\"><br> Open in Colab\n",
        "    </a>\n",
        "  </td>\n",
        "  <td style=\"text-align: center\">\n",
        "    <a href=\"https://console.cloud.google.com/vertex-ai/colab/import/https:%2F%2Fraw.githubusercontent.com%2FGoogleCloudPlatform%2Fgenerative-ai%2Fmain%2Fgemini%2Fgetting-started%2Fintro_gemini_1_5_pro.ipynb\">\n",
        "      <img width=\"32px\" src=\"https://lh3.googleusercontent.com/JmcxdQi-qOpctIvWKgPtrzZdJJK-J3sWE1RsfjZNwshCFgE_9fULcNpuXYTilIR2hjwN\" alt=\"Google Cloud Colab Enterprise logo\"><br> Open in Colab Enterprise\n",
        "    </a>\n",
        "  </td>    \n",
        "  <td style=\"text-align: center\">\n",
        "    <a href=\"https://console.cloud.google.com/vertex-ai/workbench/deploy-notebook?download_url=https://raw.githubusercontent.com/GoogleCloudPlatform/generative-ai/main/gemini/getting-started/intro_gemini_1_5_pro.ipynb\">\n",
        "      <img src=\"https://lh3.googleusercontent.com/UiNooY4LUgW_oTvpsNhPpQzsstV5W8F7rYgxgGBD85cWJoLmrOzhVs_ksK_vgx40SHs7jCqkTkCk=e14-rj-sc0xffffff-h130-w32\" alt=\"Vertex AI logo\"><br> Open in Workbench\n",
        "    </a>\n",
        "  </td>\n",
        "  <td style=\"text-align: center\">\n",
        "    <a href=\"https://github.com/GoogleCloudPlatform/generative-ai/blob/main/gemini/getting-started/intro_gemini_1_5_pro.ipynb\">\n",
        "      <img src=\"https://cloud.google.com/ml-engine/images/github-logo-32px.png\" alt=\"GitHub logo\"><br> View on GitHub\n",
        "    </a>\n",
        "  </td>\n",
        "</table>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1EExYZvij2ve"
      },
      "source": [
        "| | |\n",
        "|-|-|\n",
        "|Author(s) | [Erwin Huizenga](https://github.com/erwinh85)|"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t1DnOs6rkbOy"
      },
      "source": [
        "## Overview\n",
        "\n",
        "Gemini 1.5 Pro is a new language model from the Gemini family. This model introduces a breakthrough long context window of up to 1 million tokens that can help seamlessly analyze large amounts of information and long-context understanding. It can process text, images, audio, video, and code all together for deeper insights. Learn more about [Gemini 1.5](https://blog.google/technology/ai/google-gemini-next-generation-model-february-2024/).\n",
        "\n",
        "With this tutorial, you learn how to use the Vertex AI Gemini API and the Vertex AI SDK to work with the Gemini 1.5 Pro model to:\n",
        "\n",
        "- analyze audio for insights.\n",
        "- understand videos (including their audio components).\n",
        "- extract information from PDF documents.\n",
        "- process images, video, audio, and text simultaneously."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "61RBz8LLbxCR"
      },
      "source": [
        "## Getting Started"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "No17Cw5hgx12"
      },
      "source": [
        "### Install Vertex AI SDK for Python\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tFy3H3aPgx12"
      },
      "outputs": [],
      "source": [
        "! pip3 install --upgrade --user --quiet google-cloud-aiplatform"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R5Xep4W9lq-Z"
      },
      "source": [
        "### Restart runtime\n",
        "\n",
        "To use the newly installed packages in this Jupyter runtime, you must restart the runtime. You can do this by running the cell below, which restarts the current kernel."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XRvKdaPDTznN"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "\n",
        "if \"google.colab\" in sys.modules:\n",
        "    import IPython\n",
        "\n",
        "    app = IPython.Application.instance()\n",
        "    app.kernel.do_shutdown(True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SbmM4z7FOBpM"
      },
      "source": [
        "<div class=\"alert alert-block alert-warning\">\n",
        "<b>⚠️ The kernel is going to restart. Please wait until it is finished before continuing to the next step. ⚠️</b>\n",
        "</div>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dmWOrTJ3gx13"
      },
      "source": [
        "### Authenticate your notebook environment (Colab only)\n",
        "\n",
        "If you are running this notebook on Google Colab, run the cell below to authenticate your environment.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NyKGtVQjgx13",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1724899343716,
          "user_tz": -480,
          "elapsed": 3,
          "user": {
            "displayName": "",
            "userId": ""
          }
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8e1451f7-882a-4aed-97a1-59b3c5d35615"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING: google.colab.auth.authenticate_user() is not supported in Colab Enterprise.\n"
          ]
        }
      ],
      "source": [
        "import sys\n",
        "\n",
        "if \"google.colab\" in sys.modules:\n",
        "    from google.colab import auth\n",
        "\n",
        "    auth.authenticate_user()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DF4l8DTdWgPY"
      },
      "source": [
        "### Set Google Cloud project information and initialize Vertex AI SDK\n",
        "\n",
        "To get started using Vertex AI, you must have an existing Google Cloud project and [enable the Vertex AI API](https://console.cloud.google.com/flows/enableapi?apiid=aiplatform.googleapis.com).\n",
        "\n",
        "Learn more about [setting up a project and a development environment](https://cloud.google.com/vertex-ai/docs/start/cloud-environment)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "Nqwi-5ufWp_B",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1724995860640,
          "user_tz": -480,
          "elapsed": 4846,
          "user": {
            "displayName": "",
            "userId": ""
          }
        }
      },
      "outputs": [],
      "source": [
        "PROJECT_ID = \"<your-project-id>\"  # @param {type:\"string\"}\n",
        "LOCATION = \"us-central1\"  # @param {type:\"string\"}\n",
        "\n",
        "import vertexai\n",
        "\n",
        "vertexai.init(project=PROJECT_ID, location=LOCATION)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jXHfaVS66_01"
      },
      "source": [
        "### Import libraries\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "lslYAvw37JGQ",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1724995860641,
          "user_tz": -480,
          "elapsed": 5,
          "user": {
            "displayName": "",
            "userId": ""
          }
        }
      },
      "outputs": [],
      "source": [
        "import IPython.display\n",
        "from IPython.core.interactiveshell import InteractiveShell\n",
        "\n",
        "InteractiveShell.ast_node_interactivity = \"all\"\n",
        "\n",
        "from vertexai.generative_models import (\n",
        "    GenerationConfig,\n",
        "    GenerativeModel,\n",
        "    HarmBlockThreshold,\n",
        "    HarmCategory,\n",
        "    Part,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BY1nfXrqRxVX"
      },
      "source": [
        "### Load the Gemini 1.5 Flash model\n",
        "\n",
        "To learn more about all [Gemini API models on Vertex AI](https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#gemini-models).\n",
        "\n",
        "The Gemini model family has several model versions. You will start by using Gemini 1.5 Flash. Gemini 1.5 Flash is a more lightweight, fast, and cost-efficient model. This makes it a great option for prototyping.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "U7ExWmuLBdIA",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1725006889744,
          "user_tz": -480,
          "elapsed": 469,
          "user": {
            "displayName": "",
            "userId": ""
          }
        }
      },
      "outputs": [],
      "source": [
        "MODEL_ID = \"gemini-1.5-flash-001\"  # @param {type:\"string\"}\n",
        "\n",
        "model = GenerativeModel(MODEL_ID)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l9OKM0-4SQf8"
      },
      "source": [
        "## Vertex AI SDK basic usage\n",
        "\n",
        "Prototyping starts with calling the API to see if we get a response. Lets learn some of the funamentals of the Vertex AI Gemini model.\n",
        "\n",
        "Below is a simple example that demonstrates how to prompt the Gemini 1.5 Pro model using the Vertex AI SDK. Learn more about the [Gemini API parameters](https://cloud.google.com/vertex-ai/generative-ai/docs/model-reference/gemini#gemini-pro)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "FhFxrtfdSwOP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "executionInfo": {
          "status": "ok",
          "timestamp": 1724996051677,
          "user_tz": -480,
          "elapsed": 4191,
          "user": {
            "displayName": "",
            "userId": ""
          }
        },
        "outputId": "38fc4282-88d3-4901-9e1d-7146df7dae68"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 6 µs, sys: 2 µs, total: 8 µs\n",
            "Wall time: 12.2 µs\n",
            "total_tokens: 23\n",
            "total_billable_characters: 77\n",
            "\n",
            "\n",
            "Answer:\n",
            "As a financial analyst, I approach earnings reports with a structured process to extract meaningful insights. Here's a breakdown of my review process:\n",
            "\n",
            "**1. Pre-Earnings Preparation:**\n",
            "\n",
            "* **Company Research:** I familiarize myself with the company's industry, business model, recent developments, and any potential catalysts or headwinds. This allows me to understand the context of the report.\n",
            "* **Analyst Estimates:** I review consensus analyst estimates for revenue, earnings per share (EPS), and other key metrics. This helps me benchmark the company's performance against market expectations.\n",
            "* **Previous Reports:** I analyze the company's historical earnings releases and trends to identify patterns and potential deviations. \n",
            "\n",
            "**2. Earnings Report Review:**\n",
            "\n",
            "* **Headline Numbers:** I focus on the core financial metrics like revenue, EPS, profit margins, and cash flow. I compare these to consensus estimates and prior periods to assess the company's performance.\n",
            "* **Revenue Breakdown:** I analyze how the revenue is broken down by product, service, and region. This provides insights into the company's growth drivers and potential weaknesses.\n",
            "* **Operating Expenses:** I scrutinize operating expenses to understand cost management and identify any significant changes or trends. \n",
            "* **Balance Sheet and Cash Flow:** I review the company's balance sheet for liquidity, debt levels, working capital management, and other key financial health indicators. I also evaluate cash flow from operations, investing, and financing activities.\n",
            "\n",
            "**3. Conference Call Transcript:**\n",
            "\n",
            "* **Management Commentary:** I carefully analyze the management's commentary on the earnings call transcript. This provides valuable insights into their strategy, outlook, and response to questions.\n",
            "* **Key Metrics and Guidance:** I pay attention to any updates or revisions to guidance for the current quarter and future periods. \n",
            "* **Q&A Session:** I examine the Q&A session to identify any concerns or questions raised by analysts, and management's responses.\n",
            "\n",
            "**4. Post-Earnings Analysis:**\n",
            "\n",
            "* **Valuation and Performance:** I assess the company's valuation relative to its peers and historical trends. I look for potential implications for the stock price based on earnings performance and outlook.\n",
            "* **Competitive Landscape:** I consider how the company's results impact its competitive position within the industry.\n",
            "* **Investment Recommendation:** Based on my analysis, I formulate an investment recommendation (e.g., buy, sell, hold) and justify it with supporting data and insights.\n",
            "\n",
            "**5. Ongoing Monitoring:**\n",
            "\n",
            "* **Follow-up Research:** I continue to monitor the company's performance, industry developments, and any new information that might impact my analysis. \n",
            "* **Earnings Calls and Transcripts:** I track future earnings releases and conference calls for further insights and adjustments to my analysis.\n",
            "\n",
            "**Key Considerations:**\n",
            "\n",
            "* **Quality of Earnings:** I'm not just looking at headline numbers. I evaluate the quality of earnings, considering one-time events, accounting changes, and any potential red flags.\n",
            "* **Forward-looking Statements:** I consider the company's guidance and outlook, being aware of the inherent uncertainty in future projections.\n",
            "* **Industry and Macroeconomic Factors:** I factor in broader economic trends and industry dynamics that can influence the company's performance.\n",
            "\n",
            "This comprehensive approach helps me extract valuable insights from earnings reports and make informed investment decisions. \n",
            "\n",
            "\n",
            "Usage metadata:\n",
            "{'prompt_token_count': 32, 'candidates_token_count': 689, 'total_token_count': 721}\n",
            "\n",
            "Finish reason:\n",
            "1\n",
            "\n",
            "Safety settings:\n",
            "[category: HARM_CATEGORY_HATE_SPEECH\n",
            "probability: NEGLIGIBLE\n",
            "probability_score: 0.055908203125\n",
            "severity: HARM_SEVERITY_NEGLIGIBLE\n",
            "severity_score: 0.07470703125\n",
            ", category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
            "probability: NEGLIGIBLE\n",
            "probability_score: 0.103515625\n",
            "severity: HARM_SEVERITY_NEGLIGIBLE\n",
            "severity_score: 0.048095703125\n",
            ", category: HARM_CATEGORY_HARASSMENT\n",
            "probability: NEGLIGIBLE\n",
            "probability_score: 0.0849609375\n",
            "severity: HARM_SEVERITY_NEGLIGIBLE\n",
            "severity_score: 0.07080078125\n",
            ", category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
            "probability: NEGLIGIBLE\n",
            "probability_score: 0.10107421875\n",
            "severity: HARM_SEVERITY_NEGLIGIBLE\n",
            "severity_score: 0.0673828125\n",
            "]\n"
          ]
        }
      ],
      "source": [
        "%time\n",
        "\n",
        "# Load a example model with system instructions\n",
        "example_model = GenerativeModel(\n",
        "    MODEL_ID,\n",
        "    system_instruction=[\n",
        "        \"You are a financial analyst specialized in earnings reports\",\n",
        "    ],\n",
        ")\n",
        "\n",
        "# Set model parameters\n",
        "generation_config = GenerationConfig(\n",
        "    temperature=0.9,\n",
        "    top_p=1.0,\n",
        "    top_k=32,\n",
        "    candidate_count=1,\n",
        "    max_output_tokens=8192,\n",
        ")\n",
        "\n",
        "# Set safety settings\n",
        "safety_settings = {\n",
        "    HarmCategory.HARM_CATEGORY_HARASSMENT: HarmBlockThreshold.BLOCK_LOW_AND_ABOVE,\n",
        "    HarmCategory.HARM_CATEGORY_HATE_SPEECH: HarmBlockThreshold.BLOCK_LOW_AND_ABOVE,\n",
        "    HarmCategory.HARM_CATEGORY_SEXUALLY_EXPLICIT: HarmBlockThreshold.BLOCK_LOW_AND_ABOVE,\n",
        "    HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT: HarmBlockThreshold.BLOCK_LOW_AND_ABOVE,\n",
        "}\n",
        "\n",
        "prompt = \"\"\"\n",
        "  User input: Explain the steps you would take to review a companies earnings report?\n",
        "  Answer:\n",
        "\"\"\"\n",
        "\n",
        "# Set contents to send to the model\n",
        "contents = [prompt]\n",
        "\n",
        "# Counts tokens\n",
        "print(example_model.count_tokens(contents))\n",
        "\n",
        "# Prompt the model to generate content\n",
        "response = example_model.generate_content(\n",
        "    contents,\n",
        "    generation_config=generation_config,\n",
        "    safety_settings=safety_settings,\n",
        ")\n",
        "\n",
        "# Print the model response\n",
        "print(f\"\\nAnswer:\\n{response.text}\")\n",
        "print(f'\\nUsage metadata:\\n{response.to_dict().get(\"usage_metadata\")}')\n",
        "print(f\"\\nFinish reason:\\n{response.candidates[0].finish_reason}\")\n",
        "print(f\"\\nSafety settings:\\n{response.candidates[0].safety_ratings}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Enable streaming\n",
        "\n",
        "You can also enable streaming to recieve the output while its being generated."
      ],
      "metadata": {
        "id": "1yhiPa46BGV0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "response = example_model.generate_content(\n",
        "    contents,\n",
        "    stream=True,\n",
        "    generation_config=generation_config,\n",
        "    safety_settings=safety_settings,\n",
        ")\n",
        "\n",
        "for chunk in response:\n",
        "  print(chunk.text)\n",
        "  print(\"_\"*80)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y6H9DYnwBFmN",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1724996141284,
          "user_tz": -480,
          "elapsed": 5593,
          "user": {
            "displayName": "",
            "userId": ""
          }
        },
        "outputId": "a1fb4a0c-f668-4941-9a5f-665b4d8f15ec"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "As\n",
            "________________________________________________________________________________\n",
            " a financial analyst specializing in earnings reports, here are the steps I would take to\n",
            "________________________________________________________________________________\n",
            " review a company's earnings report:\n",
            "\n",
            "**1. Obtain the Report and\n",
            "________________________________________________________________________________\n",
            " Supporting Materials:**\n",
            "\n",
            "* **Download the Official Release:** Get the company's official press release announcing their earnings results. This is usually the first public announcement and\n",
            "________________________________________________________________________________\n",
            " contains the headline numbers.\n",
            "* **Find the Earnings Call Transcript:** Listen to or read the transcript of the company's conference call with analysts. This offers\n",
            "________________________________________________________________________________\n",
            " more detailed explanations and answers to questions from analysts.\n",
            "* **Review the 10-Q/10-K Filings:** For a more in-depth analysis, review the company's quarterly or annual report (10\n",
            "________________________________________________________________________________\n",
            "-Q or 10-K respectively) filed with the SEC. These contain detailed financial statements, management discussion and analysis (MD&A), and other relevant information.\n",
            "\n",
            "**2. Analyze the Key Metrics:**\n",
            "\n",
            "* **Revenue\n",
            "________________________________________________________________________________\n",
            ":** Look at the top-line revenue growth compared to the previous year and analyst expectations. Is it growing at a healthy rate? What are the drivers of growth?\n",
            "* **Earnings Per Share (EPS):** Examine the company's profitability by analyzing EPS. Is it beating analyst estimates? How does it compare to\n",
            "________________________________________________________________________________\n",
            " previous periods?\n",
            "* **Profit Margin:** Calculate the gross profit margin, operating margin, and net profit margin to assess the company's efficiency and pricing power.\n",
            "* **Cash Flow:** Analyze operating cash flow, investing cash flow, and financing cash flow. This gives insight into the company's ability to generate\n",
            "________________________________________________________________________________\n",
            " cash, invest in growth, and manage its finances.\n",
            "\n",
            "**3. Evaluate the Management Discussion and Analysis (MD&A):**\n",
            "\n",
            "* **Management Comments:** Pay close attention to what management says about the company's performance, future outlook, and any significant events. Look for any changes in tone or strategy.\n",
            "________________________________________________________________________________\n",
            "\n",
            "* **Risk Factors:** Read the risk factors section to understand the potential challenges and uncertainties facing the company.\n",
            "* **Guidance:** If the company provides guidance for future periods (revenue, EPS), examine how realistic it appears.\n",
            "\n",
            "**4. Compare to Industry and Competitors:**\n",
            "\n",
            "* **Benchmarking:** Compare the\n",
            "________________________________________________________________________________\n",
            " company's performance to its peers in the same industry. This helps determine if the company is outperforming or underperforming its competitors.\n",
            "* **Relative Valuation:** Use ratios like price-to-earnings (P/E) and price-to-sales (P/S) to compare the company's valuation\n",
            "________________________________________________________________________________\n",
            " to its peers.\n",
            "\n",
            "**5. Identify Key Takeaways and Potential Investment Implications:**\n",
            "\n",
            "* **Summarize:** Consolidate your findings into a clear and concise summary of the company's performance and outlook.\n",
            "* **Investment Decision:** Based on your analysis, determine if the company's earnings warrant a buy,\n",
            "________________________________________________________________________________\n",
            " sell, or hold recommendation. Consider your investment thesis and risk tolerance.\n",
            "\n",
            "**6. Continuously Monitor:**\n",
            "\n",
            "* **Follow-Up:** Stay updated on the company's performance by monitoring future earnings releases, news announcements, and analyst reports.\n",
            "* **Adjust Investment Strategy:** Regularly reassess the company's\n",
            "________________________________________________________________________________\n",
            " performance and adapt your investment strategy accordingly.\n",
            "\n",
            "**Note:** This is a general framework, and the specific steps you take may vary depending on your investment goals, industry, and the company in question.\n",
            "\n",
            "________________________________________________________________________________\n",
            "\n",
            "________________________________________________________________________________\n",
            "CPU times: user 82.4 ms, sys: 11.7 ms, total: 94.1 ms\n",
            "Wall time: 4.49 s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Token count\n",
        "**Important:** A token is equivalent to about 4 characters for Gemini models. 100 tokens are about 60-80 English words.\n",
        "[Cloud pricing](https://cloud.google.com/vertex-ai/generative-ai/pricing) is done on characters and not tokens.\n",
        "\n",
        "Using token count can help you with understanding the cost of running your prompt."
      ],
      "metadata": {
        "id": "6pAX8PQ0BhC2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Get token count\n",
        "response = model.count_tokens(prompt)\n",
        "print(f\"Prompt Token Count: {response.total_tokens}\")\n",
        "print(f\"Prompt Character Count: {response.total_billable_characters}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2EOeT5--CBTa",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1723708501021,
          "user_tz": -480,
          "elapsed": 5,
          "user": {
            "displayName": "",
            "userId": ""
          }
        },
        "outputId": "9b8a203c-86d6-4bde-fa00-2100be99b9d9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prompt Token Count: 23\n",
            "Prompt Character Count: 77\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Prompt design fundamentals\n",
        "Here are some fundamentals for designing your prompts throughout this workshop:\n",
        "- Be specific in your instructions: Craft clear and concise instructions that leave minimal room for misinterpretation.\n",
        "- - Add a few examples to your prompt: Use realistic few-shot examples to illustrate what you want to achieve.\n",
        "Break it down step-by-step: Divide complex tasks into manageable sub-goals, guiding the model through the process.\n",
        "- Specify the output format: In your prompt, ask for the output to be in the format you want, like markdown, JSON, HTML and more.\n",
        "- Put your image first for single-image prompts: While Gemini can handle image and text inputs in any order, for prompts containing a single image, it might perform better if that image (or video) is placed before the text prompt. However, for prompts that require images to be highly interleaved with texts to make sense, use whatever order is most natural."
      ],
      "metadata": {
        "id": "ElUrciMe9_Z9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Working with multimodal data\n",
        "\n",
        "Lets now dive into the world of multimodal where we will use different types of data, like a pdf and audio, and ask Gemini to reasons across these modalities."
      ],
      "metadata": {
        "id": "r8jpFgHqCvQE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Text and PDF\n",
        "\n",
        "Next, you can ask a question about the PDF document. You will use the PDF format of an earnings report. To answer this question the model has to process the PDF and find the information in the pdf."
      ],
      "metadata": {
        "id": "FL-wDJCrRHZQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ROLE = \"\"\"\n",
        "You are a financial analyst. You specialize in Give me a summary of the earnings report\n",
        "Only base your answer on the information provided.\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "aFnAXw31yoj3",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1725006648259,
          "user_tz": -480,
          "elapsed": 1464,
          "user": {
            "displayName": "",
            "userId": ""
          }
        }
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "question_1 =  \"Question: How many shares of each class of Alphabet stock were outstanding as of July 22, 2022?\"\n"
      ],
      "metadata": {
        "id": "jCP2T-fe2jzb",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1725006648259,
          "user_tz": -480,
          "elapsed": 2,
          "user": {
            "displayName": "",
            "userId": ""
          }
        }
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next you can combine the prompts with the PDF and send it to the Gemini API."
      ],
      "metadata": {
        "id": "4JS7PgyI3HAH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pdf_file_uri = \"gs://mlops-for-genai/multimodal-finanace-qa/data/unstructured/production/reports/2022/quaterly_report/20220726-alphabet-10q.pdf\"\n",
        "pdf_file = Part.from_uri(pdf_file_uri, mime_type=\"application/pdf\")\n",
        "contents = [pdf_file, ROLE, question_1]\n",
        "\n",
        "response = model.generate_content(contents)\n",
        "print(response.text)"
      ],
      "metadata": {
        "id": "EKYRfscF5_q1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "executionInfo": {
          "status": "ok",
          "timestamp": 1725006665906,
          "user_tz": -480,
          "elapsed": 11693,
          "user": {
            "displayName": "",
            "userId": ""
          }
        },
        "outputId": "0c36e5ed-6d18-484d-ae2d-112d1713be86"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "As of July 22, 2022, there were 5,996 million shares of Alphabet's Class A stock outstanding, 885 million shares of Alphabet's Class B stock outstanding, and 6,163 million shares of Alphabet's Class C stock outstanding. \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "question_2 = \"Summarize the earnings call provided and provide us with your top 3 take aways\"\n",
        "\n",
        "audio_file_uri = \"gs://github-repo/img/gemini/multimodality_usecases_overview/multimodal-finanace-alphabet-earnings-call.mp3\"\n",
        "audio_file = Part.from_uri(audio_file_uri, mime_type=\"audio/mpeg\")\n",
        "\n",
        "contents = [audio_file, ROLE, prompt]\n",
        "\n",
        "response = model.generate_content(contents)\n",
        "print(response.text)"
      ],
      "metadata": {
        "id": "Rn6q4c0V5_vb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "executionInfo": {
          "status": "ok",
          "timestamp": 1725006677582,
          "user_tz": -480,
          "elapsed": 11678,
          "user": {
            "displayName": "",
            "userId": ""
          }
        },
        "outputId": "478c03d4-125b-4142-9486-0eb3682d02d6"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The earnings call transcript does not mention the number of shares outstanding of any class of Alphabet stock. \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Troubleshooting your multimodal prompt\n",
        "While prototyping you also might have to troubleshoot your multimodal prompts. Here are some tips:\n",
        "\n",
        "- If the model is not drawing information from the relevant part of the image: Drop hints with which aspects of the image you want the prompt to draw information from.\n",
        "- If the model output is too generic (not tailored enough to the image/video input): At the start of the prompt, try asking the model to describe the image(s) or video before providing the task instruction, or try asking the model to refer to what's in the image.\n",
        "- To troubleshoot which part failed: Ask the model to describe the image, or ask the model to explain its reasoning, to gauge the model's initial understanding.\n",
        "- If your prompt results in hallucinated content: Try dialing down the temperature setting or asking the model for shorter descriptions so that it's less likely to extrapolate additional details.\n",
        "- Tuning the sampling parameters: Experiment with different temperature settings and top-k selections to adjust the model's creativity."
      ],
      "metadata": {
        "id": "xqO6ylxxDDMV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "c3xIB6n-Q_sQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Advanced reasoning across text, audio, video and PDF.\n",
        "\n",
        "Let's do something more complex. You will now let the model reason across different modalities to find the answer to the question: audio, PDF, and video.\n",
        "\n",
        "Lets also switch models and use `gemini-1.5-pro-001`"
      ],
      "metadata": {
        "id": "2amIRb-OSNM5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "MODEL_ID = \"gemini-1.5-pro-001\""
      ],
      "metadata": {
        "id": "n002WnWNbfYa",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1725007028460,
          "user_tz": -480,
          "elapsed": 479,
          "user": {
            "displayName": "",
            "userId": ""
          }
        }
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ROLE = \"You are a financial analyst at a hedge fund\"\n",
        "question_2 = \"How is Google using AI to optimize advertisement experience and what strategic partnership did Google announce in February 2023 in the automotive industry??\"\n",
        "\n",
        "audio_uri_1 = \"gs://mlops-for-genai/multimodal-finanace-qa/data/unstructured/production/earning_call/Alphabet_2023_Q1_Earnings_Call.mp3\"\n",
        "audio_uri_2 = \"gs://mlops-for-genai/multimodal-finanace-qa/data/unstructured/production/podcast/episode1.mp3\"\n",
        "\n",
        "pdf_uri_2 = \"gs://mlops-for-genai/multimodal-finanace-qa/data/unstructured/production/reports/2023/quaterly_report/20230426-alphabet-10q.pdf\"\n",
        "video_uri_1 = \"gs://mlops-for-genai/multimodal-finanace-qa/data/unstructured/production/product_launch/gemini/changing-the-way-scientists-research-Gemini.mp4\"\n",
        "\n",
        "pdf_file = Part.from_uri(pdf_uri_2, mime_type=\"application/pdf\")\n",
        "video_file = Part.from_uri(video_uri_1, mime_type=\"video/mp4\")\n",
        "audio_file_1 = Part.from_uri(audio_uri_1, mime_type=\"audio/mpeg\")\n",
        "audio_file_2 = Part.from_uri(audio_uri_2, mime_type=\"audio/mpeg\")\n",
        "\n",
        "contents = [audio_file_1, audio_file_2, video_file, pdf_file, ROLE, question_2]\n",
        "\n",
        "response = model.generate_content(contents)\n",
        "print(response.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8P_L2E4ROYTg",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1725007701693,
          "user_tz": -480,
          "elapsed": 43665,
          "user": {
            "displayName": "",
            "userId": ""
          }
        },
        "outputId": "aa6b37cf-e1d9-43fd-f3c7-bffc2f72b3e9"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Okay, here's a breakdown of how Google is using AI to optimize advertisement experiences and their partnership in the automotive industry:\n",
            "\n",
            "**AI Optimization for Ads**\n",
            "\n",
            "* **Targeting:** Google is using natural language AI to improve the relevance of ads shown to users, particularly when multiple keywords are relevant to a search query. This leads to more effective targeting and better ad performance.\n",
            "* **Bidding:** Google's smart bidding models are being enhanced to bid more accurately based on different ad formats. This ensures bids are optimized for the specific way users want to engage with an ad (e.g., a video ad vs. a text ad).\n",
            "* **Creatives:** Google has made its automatically created assets (ACA) beta available to all advertisers using English. ACA generates text assets alongside responsive search ads, using AI to reduce the manual effort needed to keep ads fresh and relevant to the user's search context.\n",
            "* **Performance Max:**  Google is actively pairing Performance Max (PMax) with core search ads, aiming to maximize conversions across all of Google's properties. Advertisers using PMax are achieving significantly higher conversion rates at a similar cost-per-acquisition (CPA).\n",
            "\n",
            "**Strategic Automotive Partnership**\n",
            "\n",
            "In February 2023, Google announced a partnership with Mercedes-Benz. This involves integrating Google Maps platform and YouTube into future Mercedes-Benz vehicles equipped with their next-generation operating system (MB.OS).\n",
            "\n",
            "**Key Aspects of the Partnership:**\n",
            "\n",
            "* **Custom Navigation:**  Mercedes-Benz can design a customized navigation interface using Google Maps.\n",
            "* **AI & Data Cloud:**  Mercedes-Benz gains access to Google's AI and data cloud capabilities, which could be used to enhance their autonomous driving technology and create a better customer experience.\n",
            "* **YouTube Integration:** This integration is likely aimed at providing Mercedes-Benz drivers with in-car entertainment and potentially a new platform for Mercedes-Benz to communicate with its customers.\n",
            "\n",
            "**In Summary:** Google is heavily leveraging AI to refine its advertising capabilities, improving targeting, bidding, and creative generation. Their partnership with Mercedes-Benz is a strategic move to extend Google's reach into the automotive industry, showcasing the potential of AI to enhance driving experiences and create new revenue opportunities. \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Experimentation\n",
        "\n",
        "Now its time for you to improve the imprompts. You can update the prompts below and re-run the code to see the response from Gemini."
      ],
      "metadata": {
        "id": "P_6z78-jd21R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ROLE = \"<update-this>\"\n",
        "question_2 = \"<update-this>\""
      ],
      "metadata": {
        "id": "J_7nr1I3eSfK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "audio_uri_1 = \"gs://mlops-for-genai/multimodal-finanace-qa/data/unstructured/production/earning_call/Alphabet_2023_Q1_Earnings_Call.mp3\"\n",
        "audio_uri_2 = \"gs://mlops-for-genai/multimodal-finanace-qa/data/unstructured/production/podcast/episode1.mp3\"\n",
        "\n",
        "pdf_uri_2 = \"gs://mlops-for-genai/multimodal-finanace-qa/data/unstructured/production/reports/2023/quaterly_report/20230426-alphabet-10q.pdf\"\n",
        "video_uri_1 = \"gs://mlops-for-genai/multimodal-finanace-qa/data/unstructured/production/product_launch/gemini/changing-the-way-scientists-research-Gemini.mp4\"\n",
        "\n",
        "pdf_file = Part.from_uri(pdf_uri_2, mime_type=\"application/pdf\")\n",
        "video_file = Part.from_uri(video_uri_1, mime_type=\"video/mp4\")\n",
        "audio_file_1 = Part.from_uri(audio_uri_1, mime_type=\"audio/mpeg\")\n",
        "audio_file_2 = Part.from_uri(audio_uri_2, mime_type=\"audio/mpeg\")\n",
        "\n",
        "#contents = [audio_file_1, audio_file_2, video_file, pdf_file, ROLE, question_2]\n",
        "contents = [audio_file_1, audio_file_2, ROLE, question_2]\n",
        "\n",
        "response = model.generate_content(contents)\n",
        "print(response.text)"
      ],
      "metadata": {
        "id": "4ENMZk0rd4q9"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "name": "basic_prototyping_with_gemini.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}